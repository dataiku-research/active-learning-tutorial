{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31eadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78da91",
   "metadata": {},
   "source": [
    "# Metrics for active learning\n",
    "\n",
    "## Contradictions\n",
    "\n",
    "We define a first metric based on contradictions. It has been observed that the number of samples on which the model changes his prediction from one iteration to the other is correlated to the improvement of accuracy. We want to verify this. Since the number of label prediction changes can be coarse, we use the absolute difference in prediction probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3848e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contradiction(previous_proba, current_proba):\n",
    "    return np.abs(current_proba - previous_proba).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec18be",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "We define a second metric based on the distance between already labeled samples and our test set. The goal of this metric is measure how well our test set has been explored by our query sampling method so far. We expect uncertainty sampling to explore the sample space located *nearby* the decision boundary and show poor exploration property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec8d549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exploration(X_selected, X_test):\n",
    "    return pairwise_distances(X_selected, X_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4392b94",
   "metadata": {},
   "source": [
    "## Compute them in an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259a12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "dataset = openml.datasets.get_dataset(1483)\n",
    "X, y, cat_indicator, names = dataset.get_data(dataset_format='array', target=dataset.default_target_attribute)\n",
    "cat_indicator = np.asarray(cat_indicator)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('encoder', OneHotEncoder(), np.where(cat_indicator)[0]),\n",
    "    ('normalizer', StandardScaler(), np.where(~cat_indicator)[0])\n",
    "], remainder='passthrough')\n",
    "\n",
    "X = ct.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cardinal.uncertainty import MarginSampler\n",
    "from cardinal.random import RandomSampler\n",
    "from cardinal.zhdanov2019 import TwoStepKMeansSampler\n",
    "from cardinal.plotting import plot_confidence_interval\n",
    "\n",
    "\n",
    "samplers = [\n",
    "    ('Random', RandomSampler(batch_size)),\n",
    "    ('Margin', MarginSampler(model, batch_size, assume_fitted=True)),\n",
    "    ('WKMeans', TwoStepKMeansSampler(10, model, batch_size, assume_fitted=True))\n",
    "]\n",
    "\n",
    "figure_accuracies = plt.figure().number\n",
    "idxs = {}\n",
    "\n",
    "for sampler_name, sampler in samplers:\n",
    "    \n",
    "    all_accuracies = []\n",
    "\n",
    "    for k in range(10):\n",
    "        idx = ActiveLearningSplitter.train_test_split(X.shape[0], test_size=500, random_state=k)\n",
    "\n",
    "        accuracies = []\n",
    "\n",
    "        # For simplicity, the first batch is simply one sample from each class\n",
    "        one_per_class = np.unique(y[idx.non_selected], return_index=True)[1]\n",
    "        idx.add_batch(one_per_class)\n",
    "\n",
    "        # A classic active learning loop\n",
    "        for j in range(n_iter):\n",
    "            model.fit(X[idx.selected], y[idx.selected])\n",
    "            accuracies.append(model.score(X[idx.test], y[idx.test]))\n",
    "            sampler.fit(X[idx.selected], y[idx.selected])\n",
    "            idx.add_batch(sampler.select_samples(X[idx.non_selected]))\n",
    "\n",
    "        all_accuracies.append(accuracies)\n",
    "    \n",
    "    # Keep the last splitter\n",
    "    idxs[sampler_name] = idx\n",
    "    \n",
    "    x_data = np.arange(10, batch_size * (n_iter - 1) + 11, batch_size)\n",
    "\n",
    "    plt.figure(figure_accuracies)\n",
    "    plot_confidence_interval(x_data, all_accuracies, label=sampler_name)\n",
    "\n",
    "plt.figure(figure_accuracies)\n",
    "plt.xlabel('Labeled samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
